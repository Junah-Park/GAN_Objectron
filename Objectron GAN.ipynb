{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\junah\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.3.56)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (19.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (3.2.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (1.18.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\junah\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\junah\\appdata\\roaming\\python\\python38\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\junah\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_objectron = mp.solutions.objectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-966511619f02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For static images:\n",
    "IMAGE_FILES = ['book.png', 'chair.png']\n",
    "with mp_objectron.Objectron(static_image_mode=True,\n",
    "                            max_num_objects=1,\n",
    "                            min_detection_confidence=0.5,\n",
    "                            model_name='Chair') as objectron:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Objectron.\n",
    "    results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw box landmarks.\n",
    "    if not results.detected_objects:\n",
    "      print(f'No box landmarks detected on {file}')\n",
    "      continue\n",
    "    print(f'Box landmarks of {file}:')\n",
    "    annotated_image = image.copy()\n",
    "    for detected_object in results.detected_objects:\n",
    "      mp_drawing.draw_landmarks(\n",
    "          annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)\n",
    "      mp_drawing.draw_axis(annotated_image, detected_object.rotation,\n",
    "                           detected_object.translation)\n",
    "      cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generated images BGR or RGB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    \"\"\" a basic GAN class \n",
    "    Extends:\n",
    "        tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GAN, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.gen = tf.keras.Sequential(self.gen)\n",
    "        self.disc = tf.keras.Sequential(self.disc)\n",
    "\n",
    "    def generate(self, z):\n",
    "        return self.gen(z)\n",
    "\n",
    "    def discriminate(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        # generating noise from a uniform distribution\n",
    "        z_samp = tf.random.normal([x.shape[0], 1, 1, self.n_Z])\n",
    "\n",
    "        # run noise through generator\n",
    "        x_gen = self.generate(z_samp)\n",
    "        # discriminate x and x_gen\n",
    "        logits_x = self.discriminate(x)\n",
    "        logits_x_gen = self.discriminate(x_gen)\n",
    "        ### losses\n",
    "        # losses of real with label \"1\"\n",
    "        disc_real_loss = gan_loss(logits=logits_x, is_real=True)\n",
    "        # losses of fake with label \"0\"\n",
    "        disc_fake_loss = gan_loss(logits=logits_x_gen, is_real=False)\n",
    "        disc_loss = disc_fake_loss + disc_real_loss\n",
    "\n",
    "        # losses of fake with label \"1\"\n",
    "        gen_loss = gan_loss(logits=logits_x_gen, is_real=True)\n",
    "\n",
    "        return disc_loss, gen_loss\n",
    "\n",
    "    def compute_gradients(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        ### pass through network\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            disc_loss, gen_loss = self.compute_loss(x)\n",
    "\n",
    "        # compute gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, self.gen.trainable_variables)\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, self.disc.trainable_variables)\n",
    "\n",
    "        return gen_gradients, disc_gradients\n",
    "\n",
    "    def apply_gradients(self, gen_gradients, disc_gradients):\n",
    "\n",
    "        self.gen_optimizer.apply_gradients(\n",
    "            zip(gen_gradients, self.gen.trainable_variables)\n",
    "        )\n",
    "        self.disc_optimizer.apply_gradients(\n",
    "            zip(disc_gradients, self.disc.trainable_variables)\n",
    "        )\n",
    "    @tf.function\n",
    "    def train(self, train_x):\n",
    "        gen_gradients, disc_gradients = self.compute_gradients(train_x)\n",
    "        self.apply_gradients(gen_gradients, disc_gradients)\n",
    "        \n",
    "        \n",
    "def gan_loss(logits, is_real=True):\n",
    "    \"\"\"Computes standard gan loss between logits and labels\n",
    "    \"\"\"\n",
    "    if is_real:\n",
    "        labels = tf.ones_like(logits)\n",
    "    else:\n",
    "        labels = tf.zeros_like(logits)\n",
    "\n",
    "    return tf.compat.v1.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=labels, logits=logits\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Z = 64\n",
    "# resembles a decoder architecture\n",
    "generator = [\n",
    "    tf.keras.layers.Dense(units=7 * 7 * 64, activation=\"relu\"),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers\n",
    "gen_optimizer = tf.keras.optimizers.Adam(0.001, beta_1=0.5)\n",
    "disc_optimizer = tf.keras.optimizers.RMSprop(0.005)# train the model\n",
    "# model\n",
    "model = GAN(\n",
    "    gen = generator,\n",
    "    disc = discriminator,\n",
    "    gen_optimizer = gen_optimizer,\n",
    "    disc_optimizer = disc_optimizer,\n",
    "    n_Z = N_Z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas dataframe to save the loss information to\n",
    "losses = pd.DataFrame(columns = ['disc_loss', 'gen_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruct(model, nex=8, zm=2):\n",
    "    samples = model.generate(tf.random.normal(shape=(BATCH_SIZE, N_Z)))\n",
    "    fig, axs = plt.subplots(ncols=nex, nrows=1, figsize=(zm * nex, zm))\n",
    "    for axi in range(nex):\n",
    "        axs[axi].matshow(\n",
    "                    samples.numpy()[axi].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
    "                )\n",
    "        axs[axi].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    for batch, train_x in tqdm(\n",
    "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
    "    ):\n",
    "        model.train(train_x)\n",
    "    # test on holdout\n",
    "    loss = []\n",
    "    for batch, test_x in tqdm(\n",
    "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\n",
    "    ):\n",
    "        loss.append(model.compute_loss(train_x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
    "    # plot results\n",
    "    display.clear_output()\n",
    "    print(\n",
    "        \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\n",
    "            epoch, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\n",
    "        )\n",
    "    )\n",
    "    plot_reconstruct(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
